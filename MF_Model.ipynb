{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('./char_embedding.pkl', 'rb')\n",
    "dict_char = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open ('./dataset/item_index_withEN.pkl', 'rb')\n",
    "item_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open ('./dataset/name_index_withEN.pkl', 'rb')\n",
    "user_index = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mat = np.load('dataset/user_item_withEN_mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_char 21592\n",
      "user_index 15251\n",
      "item_index 32\n",
      "rating_mat (15251, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"dict_char\", len(dict_char))\n",
    "print(\"user_index\", len(user_index))\n",
    "print(\"item_index\", len(item_index))\n",
    "print(\"rating_mat\", rating_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#dict_char['沈']\n",
    "#user_list.remove('')\n",
    "k, v = random.choice(list(dict_char.items()))\n",
    "print(type(v))\n",
    "#print(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15250\n",
      "missing char 190\n",
      "user_mat (15250, 256)\n",
      "user_con_mat (15250, 768)\n",
      "remain 15250\n",
      "remain (15250, 32)\n"
     ]
    }
   ],
   "source": [
    "user_list = list(user_index.keys())\n",
    "print(len(user_list))\n",
    "user_mat = []\n",
    "user_con_mat = []\n",
    "user_emb = []\n",
    "con_emb = []\n",
    "count = 0\n",
    "\n",
    "for user in user_list:\n",
    "    temp = []\n",
    "    for char in user:\n",
    "        try:\n",
    "            temp.append(dict_char[char])\n",
    "        except:\n",
    "            count += 1\n",
    "            k, v = random.choice(list(dict_char.items()))\n",
    "            temp.append(v)\n",
    "    #print(len(temp))\n",
    "    if len(temp) == 2:\n",
    "        # k, v = random.choice(list(dict_char.items()))\n",
    "        user_emb = np.mean([temp[0], temp[1]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[1]))\n",
    "    elif len(temp) == 3:\n",
    "        user_emb = np.mean([temp[0], temp[1], temp[2]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[2]))\n",
    "    elif len(temp) == 4:\n",
    "        user_emb = np.mean([temp[0], temp[1], temp[2], temp[-1]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[2]))\n",
    "    else:\n",
    "        print(\"index\", user_list.index(user))\n",
    "        #rating_mat = np.delete(rating_mat, [user_list.index(user)], axis=0)\n",
    "        user_list.remove(user)\n",
    "        del user_index[user]\n",
    "        print(len(temp))\n",
    "    user_con_mat.append(con_emb)\n",
    "    user_mat.append(user_emb)\n",
    "\n",
    "user_mat = np.array(user_mat)\n",
    "user_con_mat = np.array(user_con_mat)\n",
    "print(\"missing char\", count)\n",
    "print(\"user_mat\", user_mat.shape)\n",
    "print(\"user_con_mat\", user_con_mat.shape)\n",
    "print(\"remain\", len(user_list))\n",
    "print(\"remain\", rating_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25516173  0.02200902 -0.6367982  ...  0.27963406  0.06052778\n",
      "  -0.2570803 ]\n",
      " [-0.00804286 -0.43483147 -0.4136071  ...  0.5910477   0.11055978\n",
      "  -0.76872826]\n",
      " [-0.18077803 -0.28984937 -0.42697546 ...  0.38626578  0.0096873\n",
      "  -0.5621365 ]\n",
      " ...\n",
      " [ 0.31248116 -0.27425033  0.06705994 ...  0.5632503   0.6493718\n",
      "  -0.25115702]\n",
      " [-0.59236026  0.25725064  0.44351003 ...  0.8128228  -0.12497162\n",
      "  -0.08346231]\n",
      " [-0.06863866  0.05283417  0.21988375 ...  0.6965713   0.10992792\n",
      "  -0.58061045]]\n"
     ]
    }
   ],
   "source": [
    "#item_shape = (256, 32)\n",
    "#item_mat = np.random.rand(32, 256)\n",
    "print(user_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = 15250\n",
    "num_item = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Embedding,Reshape,Input,Dot, Dense, dot, Lambda\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(num_user, num_item, k):\n",
    "#     input_user = Input(shape=(256,),dtype=\"float32\")\n",
    "#     #model_uer = Embedding(num_user+1,k,input_length = 1)(input_uer)\n",
    "#     model_user = Dense(k, activation='relu')(input_user)\n",
    "#     model_user = Reshape((k,))(model_user)\n",
    "    \n",
    "#     input_item = Input(shape=(32,),dtype=\"float32\")\n",
    "#     model_item  = Embedding(num_item+1,k,input_length = 32)(input_item)\n",
    "#     model_item = Dense(256, activation='relu')(model_item)\n",
    "#     model_item = Reshape((256,))(model_item)\n",
    "    \n",
    "#     out = Dot(1)([model_user,model_item])\n",
    "#     model = Model(inputs=[input_user,model_item], outputs=out)\n",
    "#     model.compile(loss='mse', optimizer='Adam')\n",
    "#     model.summary()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recmand_model(num_user,num_item,k):\n",
    "    input_uer = Input(shape=(768, ),dtype=\"float32\")\n",
    "    model_uer = Dense(256, activation='relu')(input_uer)\n",
    "    model_uer = Dense(128, activation='relu')(model_uer)\n",
    "    model_uer = Dense(k, activation='relu')(model_uer)\n",
    "    \n",
    "    \n",
    "    input_item = Input(shape=(1,), dtype=\"float32\")\n",
    "    model_item  = Embedding(num_item, k, input_length = 1)(input_item)\n",
    "    model_item = Reshape((k,))(model_item)\n",
    "    \n",
    "    out = Lambda(lambda x: K.sum(x[0]*x[1], axis=-1, keepdims=True))([model_uer, model_item])\n",
    "    model = Model(inputs=[input_uer, input_item], outputs=out)\n",
    "    model.compile(loss='mse', optimizer='Adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          196864      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        2048        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 240,064\n",
      "Trainable params: 240,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Recmand_model(num_user, num_item, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "test_user = np.random.random((10, 256))\n",
    "test_item = np.random.randint(0,32, (10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77728389 0.77301389 0.98034433 ... 0.41183877 0.96137171 0.06833239]\n",
      " [0.34094176 0.52559156 0.95608407 ... 0.56940886 0.73925566 0.0494454 ]\n",
      " [0.96771409 0.84966125 0.96773883 ... 0.27405069 0.16022994 0.79279835]\n",
      " ...\n",
      " [0.51825847 0.53417301 0.26936317 ... 0.09125106 0.49868644 0.11826715]\n",
      " [0.77286229 0.05623031 0.68284393 ... 0.11435994 0.54097476 0.52244329]\n",
      " [0.13613644 0.56716673 0.6145515  ... 0.54017357 0.23930877 0.48211563]]\n"
     ]
    }
   ],
   "source": [
    "print(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 30 26  8 12 22 12 14  3 31]\n"
     ]
    }
   ],
   "source": [
    "print(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test predict\n",
    "#model.predict([np.random.random((10, 256)), np.random.randint(0,32, (10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.74557173 -0.02800325 -0.72160846 ...  0.50239176  0.42607114\n",
      "  -0.61805236]\n",
      " [-0.00291761 -0.34882382 -0.24279383 ...  0.7806603  -0.12670909\n",
      "  -1.0558528 ]\n",
      " [-0.4240876  -0.30831465  0.5773001  ...  0.01698863  0.14114247\n",
      "  -0.6353096 ]\n",
      " ...\n",
      " [-0.02675579 -0.8901479   0.57638884 ...  0.35549855  0.82068586\n",
      "   0.22624786]\n",
      " [-0.48385873  0.4444883   0.65895814 ...  1.3389612  -0.20171902\n",
      "  -0.702008  ]\n",
      " [ 0.01715979  0.4324117   0.3835889  ...  0.98461074  0.3981392\n",
      "  -0.48753178]]\n"
     ]
    }
   ],
   "source": [
    "print(user_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = 0\n",
    "item_index = 0\n",
    "train_x = []\n",
    "train_user = []\n",
    "train_item = []\n",
    "\n",
    "for u in rating_mat:\n",
    "    for i in u:\n",
    "        if i == 1:\n",
    "            # train_x.append([user_mat[user_index], [item_index]])\n",
    "            u_list = user_con_mat[user_index].tolist()\n",
    "            train_user.append(u_list)\n",
    "            #print(user_mat[user_index].tolist())\n",
    "            train_item.append(item_index)\n",
    "        item_index += 1\n",
    "    user_index += 1\n",
    "    item_index = 0\n",
    "train_x = [np.array(train_user), np.array(train_item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.74557173, -0.02800325, -0.72160846, ...,  0.50239176,\n",
      "         0.42607114, -0.61805236],\n",
      "       [-0.74557173, -0.02800325, -0.72160846, ...,  0.50239176,\n",
      "         0.42607114, -0.61805236],\n",
      "       [-0.74557173, -0.02800325, -0.72160846, ...,  0.50239176,\n",
      "         0.42607114, -0.61805236],\n",
      "       ...,\n",
      "       [-0.02675579, -0.89014792,  0.57638884, ...,  0.35549855,\n",
      "         0.82068586,  0.22624786],\n",
      "       [-0.48385873,  0.44448829,  0.65895814, ...,  1.33896124,\n",
      "        -0.20171902, -0.70200801],\n",
      "       [ 0.01715979,  0.4324117 ,  0.38358891, ...,  0.98461074,\n",
      "         0.39813921, -0.48753178]]), array([6, 7, 8, ..., 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "#train_x = np.array(train_x)\n",
    "print(train_x)\n",
    "#print(train_x)\n",
    "train_y = [1] * 39911\n",
    "train = [1] * 10\n",
    "#print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31928 samples, validate on 7983 samples\n",
      "Epoch 1/300\n",
      "31928/31928 [==============================] - 3s 81us/step - loss: 0.0128 - val_loss: 0.1897\n",
      "Epoch 2/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.9164e-04 - val_loss: 0.1911\n",
      "Epoch 3/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.8124e-04 - val_loss: 0.1926\n",
      "Epoch 4/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.7323e-04 - val_loss: 0.1911\n",
      "Epoch 5/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.4453e-04 - val_loss: 0.1919\n",
      "Epoch 6/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.9616e-04 - val_loss: 0.1933\n",
      "Epoch 7/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.0198e-04 - val_loss: 0.1936\n",
      "Epoch 8/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.3882e-04 - val_loss: 0.1938\n",
      "Epoch 9/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.2229e-04 - val_loss: 0.1939\n",
      "Epoch 10/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 9.7452e-05 - val_loss: 0.1937\n",
      "Epoch 11/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 8.8763e-05 - val_loss: 0.1944\n",
      "Epoch 12/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.2242e-04 - val_loss: 0.1943\n",
      "Epoch 13/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.2304e-04 - val_loss: 0.1945\n",
      "Epoch 14/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 1.2290e-04 - val_loss: 0.1944\n",
      "Epoch 15/300\n",
      "31928/31928 [==============================] - 2s 77us/step - loss: 9.8243e-05 - val_loss: 0.1947\n",
      "Epoch 16/300\n",
      "31928/31928 [==============================] - 2s 77us/step - loss: 5.4220e-05 - val_loss: 0.1947\n",
      "Epoch 17/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 1.3983e-04 - val_loss: 0.1961\n",
      "Epoch 18/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.3421e-05 - val_loss: 0.1964\n",
      "Epoch 19/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.3357e-05 - val_loss: 0.1966\n",
      "Epoch 20/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.0647e-05 - val_loss: 0.1968\n",
      "Epoch 21/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 8.8702e-05 - val_loss: 0.1970\n",
      "Epoch 22/300\n",
      "31928/31928 [==============================] - 2s 78us/step - loss: 1.4889e-05 - val_loss: 0.1971\n",
      "Epoch 23/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.0768e-04 - val_loss: 0.1984\n",
      "Epoch 24/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.3654e-05 - val_loss: 0.1985\n",
      "Epoch 25/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 7.9314e-05 - val_loss: 0.1989\n",
      "Epoch 26/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.5690e-05 - val_loss: 0.1988\n",
      "Epoch 27/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.6071e-05 - val_loss: 0.1986\n",
      "Epoch 28/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.2318e-05 - val_loss: 0.1993\n",
      "Epoch 29/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 4.4112e-05 - val_loss: 0.1989\n",
      "Epoch 30/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 7.0743e-05 - val_loss: 0.1988\n",
      "Epoch 31/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.2542e-05 - val_loss: 0.1988\n",
      "Epoch 32/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.0253e-05 - val_loss: 0.1991\n",
      "Epoch 33/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.4922e-05 - val_loss: 0.1994\n",
      "Epoch 34/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.1644e-05 - val_loss: 0.1990\n",
      "Epoch 35/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.2474e-05 - val_loss: 0.1992\n",
      "Epoch 36/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.2511e-05 - val_loss: 0.1992\n",
      "Epoch 37/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.1352e-05 - val_loss: 0.1992\n",
      "Epoch 38/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.2411e-05 - val_loss: 0.1988\n",
      "Epoch 39/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.0732e-05 - val_loss: 0.1990\n",
      "Epoch 40/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.6675e-05 - val_loss: 0.1992\n",
      "Epoch 41/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.1511e-05 - val_loss: 0.1992\n",
      "Epoch 42/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.7810e-05 - val_loss: 0.1997\n",
      "Epoch 43/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 6.6734e-06 - val_loss: 0.1997\n",
      "Epoch 44/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 4.8596e-05 - val_loss: 0.1998\n",
      "Epoch 45/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.4867e-05 - val_loss: 0.1997\n",
      "Epoch 46/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.3662e-05 - val_loss: 0.1999\n",
      "Epoch 47/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.6718e-06 - val_loss: 0.1999\n",
      "Epoch 48/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 3.9247e-05 - val_loss: 0.1998\n",
      "Epoch 49/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.0018e-05 - val_loss: 0.1999\n",
      "Epoch 50/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.8871e-05 - val_loss: 0.1998\n",
      "Epoch 51/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.2594e-05 - val_loss: 0.1999\n",
      "Epoch 52/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.7046e-05 - val_loss: 0.1998\n",
      "Epoch 53/300\n",
      "31928/31928 [==============================] - 2s 75us/step - loss: 2.3888e-05 - val_loss: 0.2000\n",
      "Epoch 54/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.1744e-05 - val_loss: 0.2000\n",
      "Epoch 55/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 3.2674e-05 - val_loss: 0.2001\n",
      "Epoch 56/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 5.6561e-06 - val_loss: 0.2001\n",
      "Epoch 57/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.9179e-05 - val_loss: 0.2001\n",
      "Epoch 58/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 1.9357e-05 - val_loss: 0.2002\n",
      "Epoch 59/300\n",
      "31928/31928 [==============================] - 2s 76us/step - loss: 1.2036e-05 - val_loss: 0.2003\n",
      "Epoch 60/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.1405e-05 - val_loss: 0.2002\n",
      "Epoch 61/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.5862e-05 - val_loss: 0.2000\n",
      "Epoch 62/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.5230e-05 - val_loss: 0.2000\n",
      "Epoch 63/300\n",
      "31928/31928 [==============================] - 3s 80us/step - loss: 3.2771e-06 - val_loss: 0.2000\n",
      "Epoch 64/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 2.7892e-05 - val_loss: 0.1992\n",
      "Epoch 65/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.2148e-05 - val_loss: 0.1990\n",
      "Epoch 66/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.7388e-05 - val_loss: 0.1990\n",
      "Epoch 67/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.5399e-06 - val_loss: 0.1989\n",
      "Epoch 68/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 4.1212e-05 - val_loss: 0.1989\n",
      "Epoch 69/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 9.4893e-07 - val_loss: 0.1989\n",
      "Epoch 70/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.9509e-05 - val_loss: 0.1989\n",
      "Epoch 71/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 7.0471e-06 - val_loss: 0.1990\n",
      "Epoch 72/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.4651e-05 - val_loss: 0.1988\n",
      "Epoch 73/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 4.8163e-05 - val_loss: 0.1986\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.6077e-07 - val_loss: 0.1986\n",
      "Epoch 75/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.5745e-06 - val_loss: 0.1986\n",
      "Epoch 76/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 3.1813e-05 - val_loss: 0.1985\n",
      "Epoch 77/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 1.6445e-06 - val_loss: 0.1985\n",
      "Epoch 78/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 2.5521e-05 - val_loss: 0.1984\n",
      "Epoch 79/300\n",
      "31928/31928 [==============================] - 2s 77us/step - loss: 4.3134e-06 - val_loss: 0.1984\n",
      "Epoch 80/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.5104e-05 - val_loss: 0.1983\n",
      "Epoch 81/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 2.0092e-05 - val_loss: 0.1984\n",
      "Epoch 82/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 3.3793e-06 - val_loss: 0.1984\n",
      "Epoch 83/300\n",
      "31928/31928 [==============================] - 2s 78us/step - loss: 1.5549e-05 - val_loss: 0.1983\n",
      "Epoch 84/300\n",
      "31928/31928 [==============================] - 3s 81us/step - loss: 2.3968e-05 - val_loss: 0.1983\n",
      "Epoch 85/300\n",
      "31928/31928 [==============================] - 2s 75us/step - loss: 1.0277e-05 - val_loss: 0.1983\n",
      "Epoch 86/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 1.4101e-05 - val_loss: 0.1982\n",
      "Epoch 87/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 1.6108e-05 - val_loss: 0.1982\n",
      "Epoch 88/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 1.6955e-05 - val_loss: 0.1983\n",
      "Epoch 89/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 7.4354e-06 - val_loss: 0.1990\n",
      "Epoch 90/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 8.4109e-06 - val_loss: 0.1990\n",
      "Epoch 91/300\n",
      "31928/31928 [==============================] - 3s 80us/step - loss: 2.1806e-05 - val_loss: 0.1989\n",
      "Epoch 92/300\n",
      "31928/31928 [==============================] - 2s 76us/step - loss: 8.8219e-06 - val_loss: 0.1989\n",
      "Epoch 93/300\n",
      "31928/31928 [==============================] - 3s 82us/step - loss: 7.0683e-06 - val_loss: 0.1989\n",
      "Epoch 94/300\n",
      "31928/31928 [==============================] - 2s 76us/step - loss: 2.0326e-05 - val_loss: 0.1990\n",
      "Epoch 95/300\n",
      "31928/31928 [==============================] - 3s 78us/step - loss: 3.0168e-06 - val_loss: 0.1990\n",
      "Epoch 96/300\n",
      "31928/31928 [==============================] - 3s 85us/step - loss: 2.0707e-05 - val_loss: 0.1990\n",
      "Epoch 97/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 5.5016e-06 - val_loss: 0.1990\n",
      "Epoch 98/300\n",
      "31928/31928 [==============================] - 3s 83us/step - loss: 1.6627e-05 - val_loss: 0.1986\n",
      "Epoch 99/300\n",
      "31928/31928 [==============================] - 3s 102us/step - loss: 1.1733e-05 - val_loss: 0.1986\n",
      "Epoch 100/300\n",
      "31928/31928 [==============================] - 3s 91us/step - loss: 1.0419e-05 - val_loss: 0.1986\n",
      "Epoch 101/300\n",
      "31928/31928 [==============================] - 3s 88us/step - loss: 1.1075e-05 - val_loss: 0.1986\n",
      "Epoch 102/300\n",
      "31928/31928 [==============================] - 3s 97us/step - loss: 1.4421e-05 - val_loss: 0.1986\n",
      "Epoch 103/300\n",
      "31928/31928 [==============================] - 3s 80us/step - loss: 1.3094e-05 - val_loss: 0.1986\n",
      "Epoch 104/300\n",
      "31928/31928 [==============================] - 3s 86us/step - loss: 7.1557e-06 - val_loss: 0.1986\n",
      "Epoch 105/300\n",
      "31928/31928 [==============================] - 3s 90us/step - loss: 9.6374e-06 - val_loss: 0.1986\n",
      "Epoch 106/300\n",
      "31928/31928 [==============================] - 3s 94us/step - loss: 8.5720e-06 - val_loss: 0.1986\n",
      "Epoch 107/300\n",
      "31928/31928 [==============================] - 3s 84us/step - loss: 1.4999e-05 - val_loss: 0.1986\n",
      "Epoch 108/300\n",
      "31928/31928 [==============================] - 2s 76us/step - loss: 6.1727e-06 - val_loss: 0.1986\n",
      "Epoch 109/300\n",
      "31928/31928 [==============================] - 3s 79us/step - loss: 1.4149e-05 - val_loss: 0.1986\n",
      "Epoch 110/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 8.7820e-06 - val_loss: 0.1986\n",
      "Epoch 111/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 7.2438e-06 - val_loss: 0.1986\n",
      "Epoch 112/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.1303e-05 - val_loss: 0.1986\n",
      "Epoch 113/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.5062e-05 - val_loss: 0.1986\n",
      "Epoch 114/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 5.3436e-06 - val_loss: 0.1986\n",
      "Epoch 115/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 9.3591e-06 - val_loss: 0.1986\n",
      "Epoch 116/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.3757e-06 - val_loss: 0.1986\n",
      "Epoch 117/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 2.1970e-05 - val_loss: 0.1970\n",
      "Epoch 118/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 9.9721e-07 - val_loss: 0.1970\n",
      "Epoch 119/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.1160e-05 - val_loss: 0.1970\n",
      "Epoch 120/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 9.9251e-06 - val_loss: 0.1969\n",
      "Epoch 121/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.3851e-06 - val_loss: 0.1969\n",
      "Epoch 122/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.2843e-06 - val_loss: 0.1969\n",
      "Epoch 123/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.4885e-05 - val_loss: 0.1969\n",
      "Epoch 124/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 6.9997e-06 - val_loss: 0.1969\n",
      "Epoch 125/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.3347e-05 - val_loss: 0.1969\n",
      "Epoch 126/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 9.4373e-06 - val_loss: 0.1973\n",
      "Epoch 127/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 6.5047e-06 - val_loss: 0.1974\n",
      "Epoch 128/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.2273e-05 - val_loss: 0.1974\n",
      "Epoch 129/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.9784e-06 - val_loss: 0.1974\n",
      "Epoch 130/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.4437e-05 - val_loss: 0.1973\n",
      "Epoch 131/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.7530e-06 - val_loss: 0.1972\n",
      "Epoch 132/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.5840e-05 - val_loss: 0.1976\n",
      "Epoch 133/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 4.1117e-06 - val_loss: 0.1976\n",
      "Epoch 134/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 6.0245e-06 - val_loss: 0.1977\n",
      "Epoch 135/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 7.9982e-06 - val_loss: 0.1977\n",
      "Epoch 136/300\n",
      "31928/31928 [==============================] - ETA: 0s - loss: 1.3141e-0 - 2s 71us/step - loss: 1.2908e-05 - val_loss: 0.1977\n",
      "Epoch 137/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.4907e-06 - val_loss: 0.1978\n",
      "Epoch 138/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.7935e-05 - val_loss: 0.1979\n",
      "Epoch 139/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 9.4007e-07 - val_loss: 0.1979\n",
      "Epoch 140/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.8466e-05 - val_loss: 0.1979\n",
      "Epoch 141/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 7.8289e-07 - val_loss: 0.1979\n",
      "Epoch 142/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.0335e-05 - val_loss: 0.1978\n",
      "Epoch 143/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 8.8130e-06 - val_loss: 0.1978\n",
      "Epoch 144/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.0704e-06 - val_loss: 0.1978\n",
      "Epoch 145/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.2023e-05 - val_loss: 0.1980\n",
      "Epoch 146/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 1.7516e-06 - val_loss: 0.1980\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.4045e-05 - val_loss: 0.1980\n",
      "Epoch 148/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.7147e-06 - val_loss: 0.1980\n",
      "Epoch 149/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.0423e-06 - val_loss: 0.1979\n",
      "Epoch 150/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.2978e-05 - val_loss: 0.1980\n",
      "Epoch 151/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.6847e-06 - val_loss: 0.1979\n",
      "Epoch 152/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.0321e-05 - val_loss: 0.1979\n",
      "Epoch 153/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.8358e-06 - val_loss: 0.1981\n",
      "Epoch 154/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.0598e-05 - val_loss: 0.1981\n",
      "Epoch 155/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.0977e-06 - val_loss: 0.1981\n",
      "Epoch 156/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 1.2425e-05 - val_loss: 0.1981\n",
      "Epoch 157/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.0933e-06 - val_loss: 0.1981\n",
      "Epoch 158/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 9.9112e-06 - val_loss: 0.1982\n",
      "Epoch 159/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.8859e-07 - val_loss: 0.1982\n",
      "Epoch 160/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.0822e-05 - val_loss: 0.1982\n",
      "Epoch 161/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.3725e-06 - val_loss: 0.1982\n",
      "Epoch 162/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 3.1405e-06 - val_loss: 0.1980\n",
      "Epoch 163/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 9.4348e-06 - val_loss: 0.1980\n",
      "Epoch 164/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.4398e-06 - val_loss: 0.1980\n",
      "Epoch 165/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.6391e-06 - val_loss: 0.1981\n",
      "Epoch 166/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.7354e-06 - val_loss: 0.1981\n",
      "Epoch 167/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.2873e-06 - val_loss: 0.1981\n",
      "Epoch 168/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.7252e-06 - val_loss: 0.1980\n",
      "Epoch 169/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.2338e-05 - val_loss: 0.1980\n",
      "Epoch 170/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.5657e-07 - val_loss: 0.1980\n",
      "Epoch 171/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.6433e-06 - val_loss: 0.1980\n",
      "Epoch 172/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.1268e-06 - val_loss: 0.1980\n",
      "Epoch 173/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.6460e-06 - val_loss: 0.1980\n",
      "Epoch 174/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.5807e-05 - val_loss: 0.1975\n",
      "Epoch 175/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.1011e-06 - val_loss: 0.1975\n",
      "Epoch 176/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.8789e-06 - val_loss: 0.1976\n",
      "Epoch 177/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.1689e-06 - val_loss: 0.1975\n",
      "Epoch 178/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 4.2841e-06 - val_loss: 0.1975\n",
      "Epoch 179/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.7550e-06 - val_loss: 0.1975\n",
      "Epoch 180/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 9.5834e-06 - val_loss: 0.1975\n",
      "Epoch 181/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.1500e-07 - val_loss: 0.1975\n",
      "Epoch 182/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.1254e-05 - val_loss: 0.1976\n",
      "Epoch 183/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 4.8859e-06 - val_loss: 0.1976\n",
      "Epoch 184/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 2.4329e-06 - val_loss: 0.1980\n",
      "Epoch 185/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.0262e-05 - val_loss: 0.1976\n",
      "Epoch 186/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.8331e-07 - val_loss: 0.1976\n",
      "Epoch 187/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.1929e-06 - val_loss: 0.1977\n",
      "Epoch 188/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 5.0363e-06 - val_loss: 0.1977\n",
      "Epoch 189/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.0901e-06 - val_loss: 0.1977\n",
      "Epoch 190/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.5896e-06 - val_loss: 0.1976\n",
      "Epoch 191/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.3143e-06 - val_loss: 0.1975\n",
      "Epoch 192/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.0254e-06 - val_loss: 0.1976\n",
      "Epoch 193/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.4258e-06 - val_loss: 0.1976\n",
      "Epoch 194/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.0582e-06 - val_loss: 0.1975\n",
      "Epoch 195/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.6889e-06 - val_loss: 0.1975\n",
      "Epoch 196/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 6.7319e-06 - val_loss: 0.1975\n",
      "Epoch 197/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.7334e-06 - val_loss: 0.1974\n",
      "Epoch 198/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.8132e-06 - val_loss: 0.1973\n",
      "Epoch 199/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.8343e-06 - val_loss: 0.1973\n",
      "Epoch 200/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.6368e-06 - val_loss: 0.1973\n",
      "Epoch 201/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.7901e-06 - val_loss: 0.1973\n",
      "Epoch 202/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.2021e-06 - val_loss: 0.1973\n",
      "Epoch 203/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.3071e-06 - val_loss: 0.1972\n",
      "Epoch 204/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.0814e-06 - val_loss: 0.1972\n",
      "Epoch 205/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.9367e-06 - val_loss: 0.1973\n",
      "Epoch 206/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 8.3052e-06 - val_loss: 0.1973\n",
      "Epoch 207/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.8929e-06 - val_loss: 0.1974\n",
      "Epoch 208/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.7295e-06 - val_loss: 0.1973\n",
      "Epoch 209/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.8383e-06 - val_loss: 0.1973\n",
      "Epoch 210/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.5126e-06 - val_loss: 0.1973\n",
      "Epoch 211/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.3621e-07 - val_loss: 0.1973\n",
      "Epoch 212/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.6000e-06 - val_loss: 0.1973\n",
      "Epoch 213/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 5.2008e-06 - val_loss: 0.1972\n",
      "Epoch 214/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.4038e-06 - val_loss: 0.1973\n",
      "Epoch 215/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.8015e-06 - val_loss: 0.1972\n",
      "Epoch 216/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.9119e-06 - val_loss: 0.1973\n",
      "Epoch 217/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.6704e-06 - val_loss: 0.1969\n",
      "Epoch 218/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 4.5174e-07 - val_loss: 0.1969\n",
      "Epoch 219/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.9231e-06 - val_loss: 0.1969\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.9009e-06 - val_loss: 0.1969\n",
      "Epoch 221/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.8299e-06 - val_loss: 0.1973\n",
      "Epoch 222/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.9594e-06 - val_loss: 0.1981\n",
      "Epoch 223/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.0997e-06 - val_loss: 0.1986\n",
      "Epoch 224/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 1.5447e-06 - val_loss: 0.1986\n",
      "Epoch 225/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 6.3964e-06 - val_loss: 0.1987\n",
      "Epoch 226/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.0200e-06 - val_loss: 0.1987\n",
      "Epoch 227/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 4.3991e-06 - val_loss: 0.1984\n",
      "Epoch 228/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.1915e-06 - val_loss: 0.1989\n",
      "Epoch 229/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 6.1717e-07 - val_loss: 0.1988\n",
      "Epoch 230/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 5.8428e-06 - val_loss: 0.1989\n",
      "Epoch 231/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.9694e-06 - val_loss: 0.1989\n",
      "Epoch 232/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 3.8791e-06 - val_loss: 0.1989\n",
      "Epoch 233/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.6286e-06 - val_loss: 0.1989\n",
      "Epoch 234/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 6.1479e-06 - val_loss: 0.1989\n",
      "Epoch 235/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.0104e-06 - val_loss: 0.1989\n",
      "Epoch 236/300\n",
      "31928/31928 [==============================] - 2s 69us/step - loss: 6.7318e-06 - val_loss: 0.1987\n",
      "Epoch 237/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.4800e-07 - val_loss: 0.1987\n",
      "Epoch 238/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.7467e-06 - val_loss: 0.1988\n",
      "Epoch 239/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.1801e-06 - val_loss: 0.1988\n",
      "Epoch 240/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.5221e-06 - val_loss: 0.1986\n",
      "Epoch 241/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.0191e-06 - val_loss: 0.1987\n",
      "Epoch 242/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.5614e-06 - val_loss: 0.1982\n",
      "Epoch 243/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.4324e-06 - val_loss: 0.1976\n",
      "Epoch 244/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.5230e-06 - val_loss: 0.1976\n",
      "Epoch 245/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.2328e-07 - val_loss: 0.1976\n",
      "Epoch 246/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.6593e-06 - val_loss: 0.1976\n",
      "Epoch 247/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.7964e-06 - val_loss: 0.1976\n",
      "Epoch 248/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.9373e-06 - val_loss: 0.1976\n",
      "Epoch 249/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.4936e-06 - val_loss: 0.1977\n",
      "Epoch 250/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.3440e-06 - val_loss: 0.1977\n",
      "Epoch 251/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.1465e-06 - val_loss: 0.1977\n",
      "Epoch 252/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 5.4918e-06 - val_loss: 0.1982\n",
      "Epoch 253/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.5610e-07 - val_loss: 0.1982\n",
      "Epoch 254/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 6.8289e-06 - val_loss: 0.1981\n",
      "Epoch 255/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.0606e-06 - val_loss: 0.1983\n",
      "Epoch 256/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.6311e-06 - val_loss: 0.1983\n",
      "Epoch 257/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.9228e-06 - val_loss: 0.1983\n",
      "Epoch 258/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 4.0627e-06 - val_loss: 0.1986\n",
      "Epoch 259/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.6789e-07 - val_loss: 0.1987\n",
      "Epoch 260/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.0664e-06 - val_loss: 0.1987\n",
      "Epoch 261/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.5262e-06 - val_loss: 0.1988\n",
      "Epoch 262/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.6495e-06 - val_loss: 0.1988\n",
      "Epoch 263/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.3079e-06 - val_loss: 0.1988\n",
      "Epoch 264/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.4125e-06 - val_loss: 0.1992\n",
      "Epoch 265/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.8886e-06 - val_loss: 0.1991\n",
      "Epoch 266/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.0465e-06 - val_loss: 0.1993\n",
      "Epoch 267/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.4938e-06 - val_loss: 0.1993\n",
      "Epoch 268/300\n",
      "31928/31928 [==============================] - 2s 73us/step - loss: 1.5762e-07 - val_loss: 0.1993\n",
      "Epoch 269/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 8.0666e-07 - val_loss: 0.1993\n",
      "Epoch 270/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.3658e-06 - val_loss: 0.1993\n",
      "Epoch 271/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 1.4187e-06 - val_loss: 0.1993\n",
      "Epoch 272/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.8775e-06 - val_loss: 0.1988\n",
      "Epoch 273/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.5891e-06 - val_loss: 0.1989\n",
      "Epoch 274/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.2911e-06 - val_loss: 0.1989\n",
      "Epoch 275/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.3129e-06 - val_loss: 0.1989\n",
      "Epoch 276/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 4.8470e-06 - val_loss: 0.1989\n",
      "Epoch 277/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.1268e-07 - val_loss: 0.1989\n",
      "Epoch 278/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.2087e-06 - val_loss: 0.1989\n",
      "Epoch 279/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.4711e-06 - val_loss: 0.1992\n",
      "Epoch 280/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 7.8449e-07 - val_loss: 0.1992\n",
      "Epoch 281/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.5421e-06 - val_loss: 0.1992\n",
      "Epoch 282/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 4.6619e-06 - val_loss: 0.1991\n",
      "Epoch 283/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.9643e-07 - val_loss: 0.1991\n",
      "Epoch 284/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 2.2896e-06 - val_loss: 0.1992\n",
      "Epoch 285/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.7778e-06 - val_loss: 0.1992\n",
      "Epoch 286/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 1.4905e-06 - val_loss: 0.1992\n",
      "Epoch 287/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 3.3773e-06 - val_loss: 0.1992\n",
      "Epoch 288/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 9.9475e-07 - val_loss: 0.1988\n",
      "Epoch 289/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.5034e-06 - val_loss: 0.1988\n",
      "Epoch 290/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.4777e-06 - val_loss: 0.1988\n",
      "Epoch 291/300\n",
      "31928/31928 [==============================] - 2s 71us/step - loss: 6.0170e-07 - val_loss: 0.1988\n",
      "Epoch 292/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 3.6190e-06 - val_loss: 0.1983\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31928/31928 [==============================] - 2s 69us/step - loss: 9.1534e-07 - val_loss: 0.1983\n",
      "Epoch 294/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.8968e-06 - val_loss: 0.1983\n",
      "Epoch 295/300\n",
      "31928/31928 [==============================] - 2s 74us/step - loss: 2.3683e-06 - val_loss: 0.1984\n",
      "Epoch 296/300\n",
      "31928/31928 [==============================] - 2s 77us/step - loss: 1.2492e-06 - val_loss: 0.1984\n",
      "Epoch 297/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.1635e-06 - val_loss: 0.1984\n",
      "Epoch 298/300\n",
      "31928/31928 [==============================] - 2s 70us/step - loss: 2.9078e-06 - val_loss: 0.1984\n",
      "Epoch 299/300\n",
      "31928/31928 [==============================] - 2s 72us/step - loss: 3.6680e-07 - val_loss: 0.1984\n",
      "Epoch 300/300\n",
      "31928/31928 [==============================] - 3s 83us/step - loss: 3.5802e-06 - val_loss: 0.1986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2341000fe80>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 64, epochs =300, verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_con_300.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = model.layers[2].get_weights()[0]\n",
    "embeddings = model.layers[4].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape\n",
    "# embed = embeddings.T\n",
    "# print(embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_name_dict = {'CGU':\"長庚大學\", 'CMU':\"中國醫藥大學\", 'CYCU':\"中原大學\", 'FCU':\"逢甲大學\", 'KMU':\"高雄醫學大學\", \n",
    "                'NCCU':\"政治大學\", 'NCHU':\"中興大學\", 'NCKU':\"成功大學\", 'NCTU':\"交通大學\", 'NCUE':\"彰化師範大學\", \n",
    "                'NDHU':\"東華大學\", 'NKNU':\"高雄師範大學\", 'NPTU':\"屏東大學\", 'NSYSU':\"中山大學\", 'NTCU':\"臺中教育大學\", \n",
    "                'NTHU':\"清華大學\", 'NTNU':\"臺灣師範大學\", 'NTU':\"臺灣大學\", 'NTUE':\"臺北教育大學\", 'NUTN':\"臺南大學\",\n",
    "                'SCU':\"東吳大學\", 'THU':\"東海大學\", 'TKU':\"淡江大學\", 'TNUA':\"臺北藝術大學\", 'UTAIPEI':\"臺北市立大學\",\n",
    "                'YM':\"陽明大學\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"馬崇堯\", \"周東誼\", \"鬍子元\", \"龍澳天\", \"黃智賢\"]\n",
    "#name = \"周東誼\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCharEmbed(name):\n",
    "    temp = []\n",
    "    for char in name:\n",
    "        try:\n",
    "            temp.append(dict_char[char])\n",
    "        except:\n",
    "            k, v = random.choice(list(dict_char.items()))\n",
    "            temp.append(v)\n",
    "            \n",
    "    if len(temp) == 2:\n",
    "        # k, v = random.choice(list(dict_char.items()))\n",
    "        user_emb = np.mean([temp[0], temp[1]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[1]))\n",
    "    elif len(temp) == 3:\n",
    "        user_emb = np.mean([temp[0], temp[1], temp[2]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[2]))\n",
    "    elif len(temp) == 4:\n",
    "        user_emb = np.mean([temp[0], temp[1], temp[2], temp[-1]], axis=0)\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[2]))\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            k, v = random.choice(list(dict_char.items()))\n",
    "            temp.append(v)\n",
    "        user_emb = v\n",
    "        con_emb = np.concatenate((temp[0], temp[1], temp[2]))\n",
    "    \n",
    "    return con_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = []\n",
    "for name in names:\n",
    "    u = getCharEmbed(name)\n",
    "    us.append(u)\n",
    "sc = np.array(range(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(us[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict([np.random.random((10, 256)), np.random.randint(0,32, (10))])\n",
    "#np.random.random((10, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'董事': 0,\n",
       " '董事長': 1,\n",
       " '獨立董事': 2,\n",
       " '副董事長': 3,\n",
       " '常務董事': 4,\n",
       " '執行業務股東': 5,\n",
       " 'CGU': 6,\n",
       " 'CMU': 7,\n",
       " 'CYCU': 8,\n",
       " 'FCU': 9,\n",
       " 'KMU': 10,\n",
       " 'NCCU': 11,\n",
       " 'NCHU': 12,\n",
       " 'NCKU': 13,\n",
       " 'NCTU': 14,\n",
       " 'NCUE': 15,\n",
       " 'NDHU': 16,\n",
       " 'NKNU': 17,\n",
       " 'NPTU': 18,\n",
       " 'NSYSU': 19,\n",
       " 'NTCU': 20,\n",
       " 'NTHU': 21,\n",
       " 'NTNU': 22,\n",
       " 'NTU': 23,\n",
       " 'NTUE': 24,\n",
       " 'NUTN': 25,\n",
       " 'SCU': 26,\n",
       " 'THU': 27,\n",
       " 'TKU': 28,\n",
       " 'TNUA': 29,\n",
       " 'UTAIPEI': 30,\n",
       " 'YM': 31}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open ('./dataset/item_index_withEN.pkl', 'rb')\n",
    "item_index_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "item_index_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSchool(item_index_dict, score_list):\n",
    "    broad_list = []\n",
    "    for i in range(len(score_list)):\n",
    "        if score_list[i] == 1:\n",
    "            for k, v in item_index_dict.items():\n",
    "                if v == i:\n",
    "                    broad_list.append(k)\n",
    "    return broad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "馬崇堯\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "['CGU', 'FCU', 'KMU', 'NCCU', 'NCHU', 'NCTU', 'NDHU', 'NPTU', 'NSYSU', 'NTCU', 'NTU', 'NTUE', 'NUTN', 'THU', 'TNUA', 'UTAIPEI']\n",
      "周東誼\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n",
      "鬍子元\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n",
      "龍澳天\n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "['CGU', 'CMU', 'CYCU', 'FCU', 'KMU', 'NCCU', 'NCHU', 'NCKU', 'NCTU', 'NCUE', 'NDHU', 'NKNU', 'NPTU', 'NSYSU', 'NTCU', 'NTHU', 'NTNU', 'NTU', 'NTUE', 'NUTN', 'SCU', 'THU', 'TKU', 'TNUA', 'UTAIPEI', 'YM']\n",
      "黃智賢\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['FCU', 'NSYSU', 'NTCU', 'NTU']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(us)):\n",
    "    print(names[i])\n",
    "    u = us[i]\n",
    "    score_list = []\n",
    "    for i in range(32):\n",
    "        output = model.predict([[u], [i]])\n",
    "        if output[0][0] > 0.85:\n",
    "            score_list.append(1)\n",
    "        else:\n",
    "            score_list.append(0)\n",
    "    print(score_list)\n",
    "    output_list = getSchool(item_index_dict, score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = getSchool(item_index_dict, score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CGU', 'CMU', 'CYCU', 'FCU', 'KMU', 'NCCU', 'NCHU', 'NCKU', 'NCTU', 'NCUE', 'NDHU', 'NKNU', 'NPTU', 'NSYSU', 'NTCU', 'NTHU', 'NTNU', 'NTU', 'NTUE', 'NUTN', 'SCU', 'THU', 'TKU', 'TNUA', 'UTAIPEI', 'YM']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(output_list)\n",
    "print(len(output_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSchool(name):\n",
    "    count = 0\n",
    "    max_score = 0\n",
    "    max_sc_index = 0\n",
    "    print(name)\n",
    "    u = getCharEmbed(name)\n",
    "    score_list = []\n",
    "    for i in range(32):\n",
    "        output = model.predict([[u], [i]])\n",
    "        if output[0][0] > max_score:\n",
    "            max_score = output[0][0]\n",
    "            max_sc_index = i\n",
    "        if output[0][0] > 0.85:\n",
    "            score_list.append(1)\n",
    "            count += 1\n",
    "        else:\n",
    "            score_list.append(0)\n",
    "    print(\"你會上的學校或職位有 :\", count, \"個\")\n",
    "    output_list = getSchool(item_index_dict, score_list)\n",
    "    print(\"你會上的學校或職位有 :\")\n",
    "    for out in output_list:\n",
    "        print(sc_name_dict[out], end=\", \")\n",
    "    if count > 0:\n",
    "        print(\"\\n機率最大的是:\", list(sc_name_dict.values())[max_sc_index-6])\n",
    "        #print(max_sc_index)\n",
    "    print(\"\\n\")\n",
    "    max_sc_index = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "馬崇堯\n",
      "你會上的學校或職位有 : 16 個\n",
      "你會上的學校或職位有 :\n",
      "長庚大學, 逢甲大學, 高雄醫學大學, 政治大學, 中興大學, 交通大學, 東華大學, 屏東大學, 中山大學, 臺中教育大學, 臺灣大學, 臺北教育大學, 臺南大學, 東海大學, 臺北藝術大學, 臺北市立大學, \n",
      "機率最大的是: 臺南大學\n",
      "\n",
      "\n",
      "周東誼\n",
      "你會上的學校或職位有 : 0 個\n",
      "你會上的學校或職位有 :\n",
      "\n",
      "\n",
      "鬍子元\n",
      "你會上的學校或職位有 : 0 個\n",
      "你會上的學校或職位有 :\n",
      "\n",
      "\n",
      "龍澳天\n",
      "你會上的學校或職位有 : 26 個\n",
      "你會上的學校或職位有 :\n",
      "長庚大學, 中國醫藥大學, 中原大學, 逢甲大學, 高雄醫學大學, 政治大學, 中興大學, 成功大學, 交通大學, 彰化師範大學, 東華大學, 高雄師範大學, 屏東大學, 中山大學, 臺中教育大學, 清華大學, 臺灣師範大學, 臺灣大學, 臺北教育大學, 臺南大學, 東吳大學, 東海大學, 淡江大學, 臺北藝術大學, 臺北市立大學, 陽明大學, \n",
      "機率最大的是: 逢甲大學\n",
      "\n",
      "\n",
      "黃智賢\n",
      "你會上的學校或職位有 : 4 個\n",
      "你會上的學校或職位有 :\n",
      "逢甲大學, 中山大學, 臺中教育大學, 臺灣大學, \n",
      "機率最大的是: 中山大學\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    predictSchool(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "韓國瑜\n",
      "你會上的學校或職位有 : 13 個\n",
      "你會上的學校或職位有 :\n",
      "長庚大學, 逢甲大學, 政治大學, 交通大學, 東華大學, 高雄師範大學, 屏東大學, 臺中教育大學, 臺灣大學, 臺南大學, 東海大學, 臺北藝術大學, 臺北市立大學, \n",
      "機率最大的是: 臺南大學\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictSchool(\"韓國瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黃崇明\n",
      "你會上的學校或職位有 : 6 個\n",
      "你會上的學校或職位有 :\n",
      "逢甲大學, 臺中教育大學, 臺灣大學, 臺南大學, 東海大學, 臺北藝術大學, \n",
      "機率最大的是: 臺南大學\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictSchool(\"黃崇明\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "王麒詳\n",
      "你會上的學校或職位有 : 26 個\n",
      "你會上的學校或職位有 :\n",
      "長庚大學, 中國醫藥大學, 中原大學, 逢甲大學, 高雄醫學大學, 政治大學, 中興大學, 成功大學, 交通大學, 彰化師範大學, 東華大學, 高雄師範大學, 屏東大學, 中山大學, 臺中教育大學, 清華大學, 臺灣師範大學, 臺灣大學, 臺北教育大學, 臺南大學, 東吳大學, 東海大學, 淡江大學, 臺北藝術大學, 臺北市立大學, 陽明大學, \n",
      "機率最大的是: 中山大學\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictSchool(\"王麒詳\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "趙偉廷\n",
      "你會上的學校或職位有 : 0 個\n",
      "你會上的學校或職位有 :\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictSchool(\"趙偉廷\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
